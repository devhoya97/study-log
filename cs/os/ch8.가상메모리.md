### 가상메모리
- 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 된다.
- 프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 요구 페이징 방식과 요구 세그먼테이션 방식으로 구현된다.
  - 요구 세그먼테이션 방식을 사용하는 경우는 대개 페이지드 세그먼테이션 기법을 사용하는 경우다.
  - 따라서 세부적인 구현에서는 대부분 요구 페이징 기법만이 사용된다.

### 요구 페이징(demand paging)
- 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라, 당장 사용될 페이지만을 올리는 방식
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.
  - 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있게 된다.
  - 어떤 페이지가 메모리에 존재하는지, 스왑 영역에 존재하는지 구별하기 위해 유효-무효 비트를 사용한다.

### 요구 페이징의 페이지 부재 처리
- CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 우효-무효 비트가 무효로 세팅되어 있는 경우, 페이지 부재(page fault)가 일어났다고 말한다.
  - MMU가 page fault trap을 발생시킨다.
- CPU 제어권이 커널 모드로 전환되고, 운영체제의 page fault handler가 호출되어 다음과 같은 순서로 page fault를 처리한다.
  1. 해당 페이지에 대한 접근이 적법한지 체크한다.
     - 사용되지 않는 주소 영역에 속한 페이지에 접근하려 한 경우
     - 해당 페이지에 대한 접근 권한 위반을 한 경우 (read only 페이지에 write 시도)
  2. 물리적 메모리에서 비어 있는 프레임을 할당받아 그 공간에 해당 페이지를 읽어온다.
     - 만약 비어있는 프레임이 없다면 기존에 메모리에 올라와 있는 페이지 중 하나를 스왑 아웃 시킨다.
  3. 요청된 페이지를 디스크로부터 메모리로 적재하기 까지 오랜 시간이 소요되므로, page fault를 발생시킨 프로세스는 봉쇄 상태가 된다.
  4. 디스크 입출력이 완료되어 인터럽트가 발생하면 페이지 테이블에서 해당 페이지의 유효-무효 비트를 유효로 설정하고, 봉쇄되었던 프로세스를 준비 큐로 이동시킨다.

### 요구 페이징의 성능
- page fault의 발생 빈도가 성능에 가장 큰 영향을 미친다.
  - 즉 page fault가 적게 발생할수록 요구 페이징의 성능은 향상된다.
- 유효 접근시간(effective access time)
  - 요청한 페이지를 참조하는 데 걸리는 평균 시간
  - 유효 접근 시간 = (1 - P) * 메모리 접근시간 
                  + P * (페이지 부재 발생 처리 오버헤드
                          + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드
                          + 요청된 페이지의 스왑 인 오버헤드
                          + 프로세스의 재시작 오버헤드)

### 페이지 교체(page replacement)
- page fault가 발생했는데, 물리적 메모리에 빈 프레임이 존재하지 않을 경우 페이지 교체 수행
  - 페이지 부재율을 최소하기 위한 교체 알고리즘(replacement algorithm)을 활용
  - 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는다.
  - 페이지 교체 알고리즘의 성능은 주어진 페이지 참조열(page reference string)에 대해 페이지 부재율을 계산함으로써 평가할 수 있다.
  - 페이지 참조열은 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것
- 빌레디의 최적 알고리즘
  - 가장 먼 미레에 참조될 페이지를 선정
  - 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있어야 하므로 실제 시스템에서 온라인으로 사용 불가 -> 오프라인 알고리즘
  - 다른 알고리즘의 성능에 대한 상한선을 제공한다.
- 선입선출 알고리즘
  - 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다.
  - 가장 먼저 물리적 메모리에 들어온 페이지가 계속해서 많은 참조가 이루어진다 하더라도 내쫓게 되는 비효율적인 상황이 발생
    - 물리적 메모리 공간이 늘어났음에도 오히려 성능은 더 나빠지는 FIFO 이상 현상이 발생할 수 있다.
- LRU 알고리즘 (Least Recently Used)
  - 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질인 시간지역성을 고려
  - 마지막 참조 시점이 가장 오래된 페이지를 내쫓는다.
- LFU 알고리즘 (Least Frequently Used)
  - 페이지 참조 횟수로 교체시킬 페이지를 결정
  - 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수가 가장 적었던 페이지를 쫓아낸다.
    - 최저 참조 횟수를 가진 페이지가 여러 개라면, 상대적으로 더 오래전에 참조된 페이지를 쫓아내도록 구현하는 것이 효율적
  - Incache-LFU
    - 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식
    - 따라서 페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 1부터 새롭게 시작
  - Perfect-LFU
    - 메모리에 올라와 있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트
    - 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 오버헤드가 더 크다.
  - LRU보다 오랜 시간 동안의 참조 기록을 반영할 수 있다는 장점
  - 시간에 따른 페이지 참조의 변화를 반영하지 못하고, LRU보다 구현이 복잡하다는 단점
- 클럭 알고리즘
  - 하드웨어적인 지원을 통해 알고리즘의 운영 오버헤드를 줄이는 방식
    - LRU와 LFU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하므로 알고리즘 운영에 시간적인 오버헤드가 발생
  - LRU를 근사시킨 알고리즘으로, NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로 불린다.
  - 오랫동안 참조되지 않은 페이지 중 하나를 교체한다.
    - 그러나 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못한다.
    - 알고리즘이 하드웨어적인 지원으로 동작하여 LRU에 비해 페이지 관리가 훨씬 빠르고 효율적이므로 대부분의 시스템에서 사용
  - 동작 원리
    - 메모리에 현재 올라와 있는 페이지의 참조비트 정보를 시계방향으로 따라가며 조사한다.
    - 페이지가 참조되면 참조비트가 1로 자동 세팅된다.
    - 시계바늘이 가리키는 페이지의 참조비트가 1인 경우 0으로 바꾼다.
    - 참조비트가 0인 페이지를 찾으면 그 페이지를 교체한다.
    - 적어도 시곗바늘이 한 바퀴를 도는데 소요되는 시간만큼 기회를 주기 때문에 2차 기회 알고리즘(second chance algorithm)이라고도 부른다.

### 페이지 프레임의 할당
- 할당 알고리즘 : 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정하는 방법
  - 균등할당
    - 모든 프로세스에게 페이지 프레임을 균등하게 할당
  - 비례할당
    - 프로세스의 크기에 비례해 페이지 프레임을 할당
    - 프로세스 크기를 고려한 균등할당 방식으로 볼 수 있다.
  - 우선순위 할당
    - 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당
    - 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당
- CPU에서 명령을 실행할 때는 일반적으로 여러 페이지를 동시에 참조하게 된다.
  - 명령을 실행할 때 프로세스의 주소 공간 중 코드, 데이터 스택 등 각기 다른 영역을 참조하기 때문
  - 따라서 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 한다.
  - 반복문을 실행 중인 프로세스의 경우 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 것이 유리하다.
  - 또한 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다를 수 있다.
  - 경우에 따라서 일부 프로세스에게 메모리를 할당하지 않는 방식으로 나머지 프로세스들에게 최소한의 메모리 요구량을 충족시킬 수 있어야 한다.

### 전역교체와 지역교체
- 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 어떻게 할지에 따라 교체 방법을 전역교체와 지역교체로 구분한다.
- 전역교체
  - 모든 페이지 프레임이 교체 대상
  - 페이지 교체 시 다른 프로세스에게 할당된 프레임을 빼앗아올 수 있는 방식
  - 전체 시스템 차원에서 더 자주 참조되는 페이지가 메모리에 올라가기 때문에 프로세스의 프레임 할당량이 스스로 조절된다.
- 지역교체
  - 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정
  - 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다.

### 스레싱(thrashing)
- 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 page fault rate이 크게 증가해 CPU 이용률이 급격히 떨어지는 현상
  - 운영체제 입장에서는 CPU 이용률이 낮으면 준비 큐가 비어있기 때문이라고 판단해 MPD(Multi-Programming Degree)를 높인다.
  - MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리의 양이 지나치게 감소해 page fault rate이 증가한다.
  - page fault를 처리하느라 문맥교환이 계속 발생하게 되고, CPU 이용률은 더 낮아진다. 운영체제는 MPD가 낮기 때문이라고 판단해 MPD를 더 높인다.
  - 이렇게 악순환이 반복되면서 CPU 이용률이 급격히 떨어지는 현상을 스레싱이라고 부른다.
- 하지만 실제로 MPD가 너무 낮으면, MPD를 올릴수록 CPU 이용률이 어느 지점까지는 증가한다.
  - 따라서 스레싱이 발생하지 않도록 하면서 CPU 이용률을 최대한 높일 수 있도록 MPD를 조절하는 것이 중요하다.
- MPD를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에는 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있다.

### 워킹셋 알고리즘(working-set algorithm)
- 프로세스가 일정 시간 동안 특정 주소 영역을 집중적으로 참조하는 경향이 있는데, 이 때 집중적으로 참조되는 페이지들의 집합을 지역성 집합이라고 한다.
- 워킹셋 알고리즘은 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘
- 프로세스가 일정 시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합을 워킹셋이라고 정의
  - 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 그 프로세스에게 메모리를 할당한다.
  - 그렇지 않을 경우 프로세스에게 할당된 페이지 프레임들을 모두 반납시킨 후, 그 프로세스의 주소 공간 전체를 스왑 아웃시킨다.
- 이와 같은 방법을 통해 워킹셋 알고리즘은 MPD를 조절하고 스레싱을 방지한다.
- 워킹셋을 구하는 방법
  - 특정 시점에서 워킹셋 윈도우에 포함되지 않은 페이지들은 모두 스왑아웃 시킨다?
  - 메모리에 올라와 있는 프로세스들의 워킹셋 크기의 합이 프레임의 수보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장 (MPD 감소)
  - 프로세스들의 워킹셋을 모두 할당한 후에도 프레임이 남을 경우, 스왑 아웃되었던 프로세스를 다시 메모리에 올려서 워킹셋을 할당 (MPD 증가)
- 윈도우의 크기가
  - 너무 작으면 지역성 집합을 모두 수용하지 못할 우려가 있고
  - 너무 크면 여러 규모의 지역성 집합을 수용할 수 있는 반면 MPD가 감소해 CPU 이용률이 낮아질 우려가 있다.
- 워킹셋 알고리즘에서 시스템의 성능을 향상시키기 위해서는 프로세스들의 지역성 집합을 효과적으로 탐지할 수 있는 윈도우 크기를 결정하는 것이 중요하다.
- 윈도우의 크기가 일정해도 워킹셋의 크기는 시간이 흐름에 따라 변한다.
  - 덕분에 워킹셋 알고리즘은 프로세스가 메모리를 많이 필요로 할 때에는 많이 할당하고, 적게 필요로 할 때에는 적게 할당하는 일종의 동적인 프레임 할당 기능까지 수행하게 된다.

### 페이지 부재 빈도 알고리즘(page fault frequency scheme)
- 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절
  - 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해놓은 상한값을 넘게 되면, 이 프로세스에 할당된 프레임의 수가 부족하다고 판단하여 추가로 할당
  - 이 때 추가로 할당할 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 MPD를 조절한다.
  - 반면 프로세스의 페이지 부재율이 하한값 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프렝미이 할당된 것으로 간주해 할당된 프레임의 수를 줄인다.
  - 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑 아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높인다.
- 페이지 부재 빈도 알고리즘에서는 이러한 원리로 MPD를 조절하면서 CPU 이용률을 높이는 동시에 스레싱을 방지한다.
